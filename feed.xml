<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://roboxiv.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://roboxiv.com/" rel="alternate" type="text/html" /><updated>2025-03-16T09:43:29+00:00</updated><id>https://roboxiv.com/feed.xml</id><title type="html">Minho’s Blog</title><subtitle>Spatial AI and Robotics</subtitle><author><name>Minho Lee</name></author><entry><title type="html">Isaac Lab Tutorial #2 - Create the Scene</title><link href="https://roboxiv.com/simulation/2025/02/23/isaaclab-tutorial-interacting-with-objects/" rel="alternate" type="text/html" title="Isaac Lab Tutorial #2 - Create the Scene" /><published>2025-02-23T00:00:00+00:00</published><updated>2025-02-23T00:00:00+00:00</updated><id>https://roboxiv.com/simulation/2025/02/23/isaaclab-tutorial-interacting-with-objects</id><content type="html" xml:base="https://roboxiv.com/simulation/2025/02/23/isaaclab-tutorial-interacting-with-objects/"><![CDATA[<table>
  <thead>
    <tr>
      <th>Previous Tutorial</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>🔗 <a href="https://www.roboxiv.com/simulation/2025/02/08/isaaclab-tutorial-intro/">Isaac Lab Tutorial #1</a></td>
      <td>Overview of Isaac Lab &amp; Setting up the Docker Environment</td>
    </tr>
  </tbody>
</table>

<p>📌 두 번째 튜토리얼에서는 Standalone Python 스크립트를 사용하여 Isaac Sim 시뮬레이터를 실행하고, Isaac Lab의 장면에 다양한 객체 또는 프리미티브를 불러오는 방법을 살펴본다.</p>

<h3 id="1-creating-an-empty-scene">1. Creating an empty scene</h3>
<p>NVIDIA Omniverse의 기본적인 워크플로우는 크게 세 가지로 나뉜다.</p>
<ul>
  <li>GUI: 직관적인 시각적 인터페이스를 통해 가상 세계를 구성하고 로봇 조립 및 센서 부착 등의 작업을 수행하는 데 적합하다.</li>
  <li>Extensions: 비동기 실행 및 실시간 변경을 지원하며, 적응형 물리 엔진을 활용해 인터랙티브 GUI와 실시간 애플리케이션 구현하는 데 유용하다.</li>
  <li><b>Standalone Python</b>: 물리 및 렌더링 타이밍을 직접 제어할 수 있으며, headless 모드로 대규모 강화학습 및 동적 환경 생성을 효율적으로 수행할 수 있다.</li>
</ul>

<p>본 섹션에서는 독립 실행형 파이썬(Standalone Python) 스크립트를 사용하여 시뮬레이션 애플리케이션을 시작하고 빈 장면을 생성하는 기본적인 방법을 소개한다. 마지막에는 <mark>argparse.ArgumentParser</mark>에 명령줄 옵션을 추가하는 방법을 설명하며, <mark>AppLauncher.add_app_launcher_args()</mark> 메서드에 파서 인스턴스를 전달하여 다양한 매개변수를 추가하는 과정을 다룬다. 여기에는 headless 모드 설정, 다양한 Livestream(해상도 및 출력) 조정, 오프스크린 렌더링 활성화 등 사용자 정의 시뮬레이션을 설정하는 옵션이 포함된다.</p>

<h4 id="11-launching-the-simulator">1.1. Launching the simulator</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">isaaclab.app</span> <span class="kn">import</span> <span class="n">AppLauncher</span>

<span class="c1"># create argparser
</span><span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s">"Creating an empty stage."</span><span class="p">)</span>
<span class="c1"># append AppLauncher CLI args
</span><span class="n">AppLauncher</span><span class="p">.</span><span class="n">add_app_launcher_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
<span class="c1"># parse the arguments
</span><span class="n">args_cli</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="n">parse_args</span><span class="p">()</span>
<span class="c1"># launch omniverse app
</span><span class="n">app_launcher</span> <span class="o">=</span> <span class="n">AppLauncher</span><span class="p">(</span><span class="n">args_cli</span><span class="p">)</span>
<span class="n">simulation_app</span> <span class="o">=</span> <span class="n">app_launcher</span><span class="p">.</span><span class="n">app</span>
</code></pre></div></div>
<p><mark>isaaclab.app</mark> 모듈의 <mark>AppLauncher</mark> 클래스는 Omniverse Isaac Sim 애플리케이션을 실행하는 역할을 한다. <mark>AppLauncher.add_app_launcher_args(parser)</mark>를 호출하면 애플리케이션 실행에 필요한 기본적인 CLI 인자가 <mark>parser</mark>에 추가된다. 이후 <mark>AppLauncher(args_cli)</mark>를 호출하면 애플리케이션 실행 객체가 생성되며, <mark>app_launcher.app</mark>을 통해 시뮬레이션 애플리케이션 객체(<mark>simulation_app</mark>)를 가져올 수 있다.</p>

<h4 id="12-importing-python-modules">1.2. Importing python modules</h4>
<p>시뮬레이션 앱이 실행되면 Isaac Sim 및 기타 라이브러리에서 다양한 Python 모듈을 가져올 수 있다. 아래에서는 다음 모듈을 가져오는 예시다.</p>
<ul>
  <li><mark>isaaclab.sim</mark>: 시뮬레이터와 관련된 모든 핵심 작업을 위한 Isaac Lab의 하위 패키지</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">isaaclab.sim</span> <span class="kn">import</span> <span class="n">SimulationCfg</span><span class="p">,</span> <span class="n">SimulationContext</span>
</code></pre></div></div>

<h4 id="13-configuring-the-simulation-context">1.3. Configuring the simulation context</h4>
<p>독립 실행형 스크립트에서 시뮬레이션을 시작할 때 <mark>sim.SimulationContext</mark> 클래스를 통해 시뮬레이터 재생, 일시 정지 및 단계별 실행 제어뿐만 아니라 다양한 타임라인 이벤트 처리 및 물리 장면 구성을 수행할 수 있다. 아래 스크립트에서는 물리 및 렌더링의 시간 간격(time step)을 0.01초로 설정하고 있으며, 이를 위해 해당 값을 <mark>sim.SimulationCfg</mark>에 전달한 후 시뮬레이션 컨텍스트의 인스턴스를 생성한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Initialize the simulation context
</span><span class="n">sim_cfg</span> <span class="o">=</span> <span class="n">SimulationCfg</span><span class="p">(</span><span class="n">dt</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">SimulationContext</span><span class="p">(</span><span class="n">sim_cfg</span><span class="p">)</span>
<span class="c1"># Set main camera
</span><span class="n">sim</span><span class="p">.</span><span class="n">set_camera_view</span><span class="p">([</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</code></pre></div></div>
<p>위 예제에서는 시뮬레이션 컨텍스트를 생성한 후, 시뮬레이션된 장면에서 작동하는 물리 엔진(physics)만 설정하였다. 여기에는 시뮬레이션에 사용할 장치(device), 중력 벡터(gravity vector), 기타 고급 솔버 매개변수(advanced solver parameters) 등이 포함된다. 이제 시뮬레이션 실행을 위해 다음 두 가지 주요 단계가 남아있다.</p>
<ul>
  <li><b>시뮬레이션 장면 설계</b>: 센서, 로봇 및 기타 시뮬레이션 객체 추가</li>
  <li><b>시뮬레이션 루프 실행</b>: 시뮬레이터 단계별 실행 및 데이터 설정 및 가져오기</li>
</ul>

<p>이번 튜토리얼에서는 <b>빈 장면에서의 시뮬레이션 제어(2단계)</b>만 다룬다. 다음 튜토리얼에서는 <b>객체 추가 및 상호 작용을 위한 시뮬레이션 핸들 작업(1단계)</b>을 살펴볼 예정이다.</p>

<h4 id="14-running-the-simulation">1.4. Running the simulation</h4>
<p>시뮬레이션 장면을 설정한 후 가장 먼저 해야 할 일은 <mark>sim.SimulationContext.reset()</mark> 메서드를 호출하는 것이다. 이 메서드는 타임라인을 시작하고, 시뮬레이터에서 물리 핸들(physics handles)을 초기화하는 역할을 한다. 시뮬레이션을 실행하기 전에 반드시 처음에 호출해야 하며, 그렇지 않으면 시뮬레이션 핸들이 올바르게 초기화되지 않는다.</p>

<p>아래 코드 스니펫은 시뮬레이션 타임라인을 시작한 후, 애플리케이션이 실행되는 동안 반복적으로 시뮬레이션 단계를 진행하는 간단한 시뮬레이션 루프를 설정하는 예제이다. <mark>sim.SimulationContext.step()</mark> 메서드는 <mark>render</mark> 인자를 받아 실행되며, 이 값에 따라 렌더링 관련 이벤트를 포함할지 여부가 결정된다. 기본적으로 <mark>render</mark> 값은 <mark>True</mark>로 설정되어 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Play the simulator
</span><span class="n">sim</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"[INFO]: Simulator Setup complete..."</span><span class="p">)</span>

<span class="c1"># Simulate physics
</span><span class="k">while</span> <span class="n">simulation_app</span><span class="p">.</span><span class="n">is_running</span><span class="p">():</span>
    <span class="c1"># perform step
</span>    <span class="n">sim</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="15-exiting-the-simulation">1.5. Exiting the simulation</h4>
<p>마지막으로, <mark>isaacsim.SimulationApp.close()</mark> 메서드를 호출하여 시뮬레이션을 중지하고 해당 창을 닫을 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># close sim app
</span><span class="n">simulation_app</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="16-test-code-execution">1.6. Test Code Execution</h3>
<p>이제 아래 명령어를 통해 스크립트를 실행하면 시뮬레이션이 시작되고 스테이지가 렌더링되는 결과를 확인할 수 있다.
시뮬레이션을 중지하려면 창을 닫거나 터미널에서 <mark>Ctrl+C</mark>을 입력하면 된다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./isaaclab.sh <span class="nt">-p</span> scripts/tutorials/00_sim/create_empty.py
</code></pre></div></div>

<h3 id="2-spawning-prims-into-the-scene">2. Spawning prims into the scene</h3>

<h4 id="21-key-concepts-of-usd">2.1. Key concepts of USD</h4>
<p>Omniverse의 장면 디자인은 USD(Universal Scene Description)라는 파일 형식을 중심으로 구축된다. USD 파일을 통해 계층적 방식으로 3D 장면을 구성할 수 있으며, USD에 대한 자세한 설명은 아래 페이지를 통해 확인해보는 것을 추천한다.</p>

<ul>
  <li><a href="https://openusd.org/docs/index.html"> Introduction to USD</a></li>
</ul>

<p>본 튜토리얼을 이해하기 위해 꼭 알아야 할 USD의 개념은 다음과 같다.<br /></p>
<ol>
  <li><b>Primitive (Prim)</b>: USD 장면의 기본 구성 요소로 장면 그래프의 노드(node)라고 볼 수 있다. 각 노드는 메시(mesh), 광원(light), 카메라(camera) 또는 변환(transform)일 수 있다.</li>
  <li><b>Attribute</b>: Prim이 가지는 속성(attribute)으로 키-값(key-value) 쌍의 형태를 띤다. 예를 들어, 특정 prim이 <i>color</i>라는 속성을 가지며, 그 값이 <i>red</i>일 수도 있다.</li>
  <li><b>Relationship</b>: Prim 간의 연결을 나타낸다. 이는 다른 prim을 참조하는 포인터와 같은 개념으로, 예를 들어 메시(mesh) prim이 shading을 위한 material prim과 관계를 가질 수 있다.</li>
  <li><b>Stage</b>: 프리미티브(prim)와 속성(attribute) 및 관계(relationship)의 모음을 USD 스테이지(stage)라고 한다. 이는 장면의 모든 prim을 위한 컨테이너로 생각할 수 있다. 즉, USD 스테이지는 장면을 구성하는 모든 prim을 관리하는 공간이며, 장면을 디자인한다는 것은 곧 USD stage를 구성하는 것과 같다.</li>
</ol>

<p>Isaac Lab에서는 USD API를 기반으로 configuration-driven 인터페이스를 제공하여 장면에 prim을 생성할 수 있다. 이는 <mark>sim.spawners</mark> 모듈에 포함되어 있다.</p>

<ul>
  <li><a href="https://isaac-sim.github.io/IsaacLab/main/source/api/lab/isaaclab.sim.spawners.html"> Isaac Lab API Reference: isaaclab.sim.spawners</a></li>
</ul>

<p>장면에 prim을 생성할 때 각 prim에는 속성과 관계를 정의하는 구성 클래스 인스턴스가 필요하다. 이 구성 클래스가 해당 함수에 전달되어 prim 이름과 변환이 지정된다. 그런 다음 함수가 장면에 prim을 생성한다.</p>

<p>개략적으로 보면 작동 방식은 아래와 같다.</p>
<ol>
  <li>설정 클래스 인스턴스 생성</li>
  <li>해당 spawner 함수를 사용하여 prim을 장면에 배치하거나 설정 클래스에서 직접 spawner 함수를 호출</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a configuration class instance
</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">MyPrimCfg</span><span class="p">()</span>
<span class="n">prim_path</span> <span class="o">=</span> <span class="s">"/path/to/prim"</span>

<span class="c1"># Spawn the prim into the scene using the corresponding spawner function
</span><span class="n">spawn_my_prim</span><span class="p">(</span><span class="n">prim_path</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">orientation</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="c1"># OR
# Use the spawner function directly from the configuration class
</span><span class="n">cfg</span><span class="p">.</span><span class="n">func</span><span class="p">(</span><span class="n">prim_path</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">orientation</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div></div>

<blockquote>
  <p>⚠️ <strong>[Attention]</strong> <br />
모든 장면 구성은 시뮬레이션이 시작되기 전에 이루어져야 한다. 시뮬레이션이 시작되면 장면을 고정하고 prim의 속성만 변경하는 것이 좋다. 시뮬레이션 중 새로운 prim을 추가하면 GPU 물리 시뮬레이션 버퍼가 변경되어 예상치 못한 동작이 발생할 수 있기 때문이다.</p>
</blockquote>

<h4 id="22-reference-script-guide">2.2. Reference Script Guide</h4>
<p>이제 장면에 지면 평면(Ground Plane)과 조명, 큐브와 구, 실린더와 같은 기본 형상 및 다른 .USD, .URDF 또는 .OBJ 파일과 같은 다른 파일 형식에서 prim을 스폰하는 방법을 간단한 예시를 통해 알아보자.</p>

<ol>
  <li>지면 평면 생성: <mark>GroundPlaneCfg</mark> 모양과 크기 등의 변경 가능한 속성을 갖는 격자 모양의 접지면을 구성한다.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spawn ground-plane
</span><span class="n">cfg_ground</span> <span class="o">=</span> <span class="n">sim_utils</span><span class="p">.</span><span class="n">GroundPlaneCfg</span><span class="p">()</span>
<span class="n">cfg_ground</span><span class="p">.</span><span class="n">func</span><span class="p">(</span><span class="s">"/World/defaultGroundPlane"</span><span class="p">,</span> <span class="n">cfg_ground</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>조명 생성: 장면에 조명 설정을 불러온다. 여기에는 원거리 조명(distant lights), 구형 조명(sphere lights), 디스크 조명(disk lights), 원통형 조명(cylinder lights)이 포함된다.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spawn distant light
</span><span class="n">cfg_light_distant</span> <span class="o">=</span> <span class="n">sim_utils</span><span class="p">.</span><span class="n">DistantLightCfg</span><span class="p">(</span>
 <span class="n">intensity</span><span class="o">=</span><span class="mf">3000.0</span><span class="p">,</span>
 <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">cfg_light_distant</span><span class="p">.</span><span class="n">func</span><span class="p">(</span><span class="s">"/World/lightDistant"</span><span class="p">,</span> <span class="n">cfg_light_distant</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div>    </div>
  </li>
  <li>기본 형상 생성:
    <ul>
      <li>기본 형상을 생성하기 전에, <b>Transform Primitive(Xform)</b>의 개념을 이해해야 한다. Xform은 변환(transformation) 속성만 포함하는 기본 요소(primitive)로 다른 prim을 그 아래에 그룹화(parent-child 관계)하고 그룹 전체를 변형하는 데 사용된다. 아래는 Xform Prim을 생성하여 하위에 있는 모든 기본 형상을 그룹화하는 예제이다.</li>
    </ul>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a new xform prim for all objects to be spawned under
</span><span class="n">prim_utils</span><span class="p">.</span><span class="n">create_prim</span><span class="p">(</span><span class="s">"/World/Objects"</span><span class="p">,</span> <span class="s">"Xform"</span><span class="p">)</span>
</code></pre></div></div>

<p>다음으로, <mark>ConeCfg</mark> 클래스를 사용하여 원뿔의 반경, 높이, <b>[2] 물리 속성 및 재료 속성을 지정</b>하여 원뿔 형상을 생성하는 예시는 아래와 같다. (<b>[1] 기본적으로 물리 및 재료 속성은 비활성화</b>된다.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spawn a red cone (without physics and material properties)
</span><span class="n">cfg_cone</span> <span class="o">=</span> <span class="n">sim_utils</span><span class="p">.</span><span class="n">ConeCfg</span><span class="p">(</span>
    <span class="n">radius</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">visual_material</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">PreviewSurfaceCfg</span><span class="p">(</span><span class="n">diffuse_color</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)),</span>
<span class="p">)</span>
<span class="n">cfg_cone</span><span class="p">.</span><span class="n">func</span><span class="p">(</span><span class="s">"/World/Objects/Cone1"</span><span class="p">,</span> <span class="n">cfg_cone</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">cfg_cone</span><span class="p">.</span><span class="n">func</span><span class="p">(</span><span class="s">"/World/Objects/Cone2"</span><span class="p">,</span> <span class="n">cfg_cone</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
</code></pre></div></div>

<p>아래는 강체 물리(Rigid body physics)를 추가하여 원뿔의 질량, 마찰 및 복원력을 지정하는 예시다. 만약 이를 따로 지정하지 않으면 USD Physics의 기본값이 적용된다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spawn a green cone with colliders and rigid body (with rigid body physics)
</span><span class="n">cfg_cone_rigid</span> <span class="o">=</span> <span class="n">sim_utils</span><span class="p">.</span><span class="n">ConeCfg</span><span class="p">(</span>
    <span class="n">radius</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">rigid_props</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">RigidBodyPropertiesCfg</span><span class="p">(),</span>
    <span class="n">mass_props</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">MassPropertiesCfg</span><span class="p">(</span><span class="n">mass</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
    <span class="n">collision_props</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">CollisionPropertiesCfg</span><span class="p">(),</span>
    <span class="n">visual_material</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">PreviewSurfaceCfg</span><span class="p">(</span><span class="n">diffuse_color</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)),</span>
<span class="p">)</span>
<span class="n">cfg_cone_rigid</span><span class="p">.</span><span class="n">func</span><span class="p">(</span>
    <span class="s">"/World/Objects/ConeRigid"</span><span class="p">,</span> <span class="n">cfg_cone_rigid</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span> <span class="n">orientation</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<p>마지막으로, 변형 가능한 물리 속성(Deformable body physics)을 포함하는 직육면체를 생성하는 예시다. 강체 시뮬레이션과 달리 변형 가능한 객체는 각 꼭짓점(vertex) 사이에 상대적인 움직임이 가능하다. 이는 천, 고무 또는 젤리와 같은 부드러운 재질을 갖는 객체를 시뮬레이션하는 데 유용하다. 변형 가능한 물리 속성은 GPU 시뮬레이션에서만 지원된다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spawn a blue cuboid with deformable body
</span><span class="n">cfg_cuboid_deformable</span> <span class="o">=</span> <span class="n">sim_utils</span><span class="p">.</span><span class="n">MeshCuboidCfg</span><span class="p">(</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
    <span class="n">deformable_props</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">DeformableBodyPropertiesCfg</span><span class="p">(),</span>
    <span class="n">visual_material</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">PreviewSurfaceCfg</span><span class="p">(</span><span class="n">diffuse_color</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)),</span>
    <span class="n">physics_material</span><span class="o">=</span><span class="n">sim_utils</span><span class="p">.</span><span class="n">DeformableBodyMaterialCfg</span><span class="p">(),</span>
<span class="p">)</span>
<span class="n">cfg_cuboid_deformable</span><span class="p">.</span><span class="n">func</span><span class="p">(</span><span class="s">"/World/Objects/CuboidDeformable"</span><span class="p">,</span> <span class="n">cfg_cuboid_deformable</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
</code></pre></div></div>

<ol>
  <li>다른 파일에서 불러오기: USD, URDF 또는 OBJ 파일과 같은 다른 파일 형식에서 객체를 불러올 수 있다. 아래 예시에서는 테이블의 USD 파일을 장면에 추가한다. 테이블은 mesh primitive이며, 연관된 material primitive가 있다. 이 모든 정보는 USD 파일에 저장되어 있다.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spawn a usd file of a table into the scene
</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">sim_utils</span><span class="p">.</span><span class="n">UsdFileCfg</span><span class="p">(</span><span class="n">usd_path</span><span class="o">=</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">ISAAC_NUCLEUS_DIR</span><span class="si">}</span><span class="s">/Props/Mounts/SeattleLabTable/table_instanceable.usd"</span><span class="p">)</span>
<span class="n">cfg</span><span class="p">.</span><span class="n">func</span><span class="p">(</span><span class="s">"/World/Objects/Table"</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">translation</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>
</code></pre></div></div>

<p>이 튜토리얼과 관련된 보다 자세한 내용은 아래 링크에서 확인할 수 있다.</p>
<ul>
  <li><a href="https://isaac-sim.github.io/IsaacLab/main/source/tutorials/00_sim/spawn_prims.html"> Isaac Lab Documentation: Spawning prims into the scene</a></li>
</ul>

<h4 id="23-executing-the-script">2.3. Executing the Script</h4>
<p>아래 명령어를 통해 위에서 설명한 장면 구성을 하는 예제 스크립트를 실행할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./isaaclab.sh <span class="nt">-p</span> scripts/tutorials/00_sim/spawn_prims.py
</code></pre></div></div>

<p>시뮬레이션이 시작되면 아래 영상과 같이 지면 평면, 조명, 원뿔 객체, 테이블이 나타난 화면이 보여진다. 강체 물리가 활성화된 녹색 원뿔은 떨어져서 테이블과 지면 평면과 충돌해야 하며, 다른 빨간색 원뿔은 시각적 요소이므로 움직이지 않는 것을 볼 수 있다.</p>

<video width="640" height="360" controls="">
  <source src="/assets/img/blog/20250223/isaaclab_spawn_prim_demo.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<p>이번 포스팅에서는 <b>기본적인 시뮬레이션 장면 구성 방법</b>을 살펴보았다. 다음 포스팅에서는 <b>강체(rigid object), 관절(articulation), 변형 가능한 객체(deformable object)를 불러오고 상호작용</b> 하는 방법에 대해 알아보도록 하자!</p>

<hr />]]></content><author><name>Minho Lee</name></author><category term="[&quot;Simulation&quot;]" /><category term="Robotics" /><category term="Isaac Lab" /><category term="Isaac Sim" /><summary type="html"><![CDATA[Previous Tutorial Description 🔗 Isaac Lab Tutorial #1 Overview of Isaac Lab &amp; Setting up the Docker Environment]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roboxiv.com/assets/img/thumbnails/blog_3.png" /><media:content medium="image" url="https://roboxiv.com/assets/img/thumbnails/blog_3.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Isaac Lab Tutorial #1 - Introduction</title><link href="https://roboxiv.com/simulation/2025/02/08/isaaclab-tutorial-intro/" rel="alternate" type="text/html" title="Isaac Lab Tutorial #1 - Introduction" /><published>2025-02-08T00:00:00+00:00</published><updated>2025-02-08T00:00:00+00:00</updated><id>https://roboxiv.com/simulation/2025/02/08/isaaclab-tutorial-intro</id><content type="html" xml:base="https://roboxiv.com/simulation/2025/02/08/isaaclab-tutorial-intro/"><![CDATA[<p>📌 최근 로봇 연구에서 <strong>로보틱스 시뮬레이션</strong>은 모델 성능 검증, 학습 워크플로우 구축, 대규모 합성데이터 생성 등 다양한 목적으로 활용되고 있다. 로봇 학습 및 시뮬레이션을 위한 여러 플랫폼이 존재하는 가운데, NVIDIA의 Isaac Lab은 GPU 가속, CUDA, TensorRT 등의 딥러닝 SDK와 Omniverse Isaac Sim을 기반으로 고품질 그래픽과 실시간 레이트레이싱을 지원하는 가상환경을 제공한다. 이러한 특징들은 Embodied AI를 연구하는 연구자들에게 강력하고 효과적인 솔루션이 될 수 있다.</p>

<p>나 역시도 Isaac Lab이 제공하는 기능들을 공부하는 것은 향후 연구에 많은 도움이 될 것이라 생각이 들었다. 그래서, <strong>Isaac Lab의 기본적인 튜토리얼부터 토이 프로젝트를 거쳐 실제 연구 적용까지의 과정을 정리하여 포스팅하려고 한다.</strong></p>

<h3 id="1-before-getting-started">1. Before Getting Started</h3>
<h4 id="11-ngcnvidia-gpu-cloud-container">1.1. NGC(NVIDIA GPU Cloud) Container</h4>
<p align="center"><img src="/assets/img/blog/20250208/fig_1.png" /></p>

<p>NGC에서는 AI, 머신 러닝 및 고성능 컴퓨팅(HPC)을 위한 컨테이너을 제공하며, 사전 학습된 AI 모델과 시각화 도구를 포함한 소프트웨어 스택을 지원한다. AI 모델 구축은 복잡하고 많은 시간이 소요되는데 NGC의 통합 컨테이너 기술은 배포 워크플로우를 간소화하고 AI 프로젝트를 가속화하는 데 도움을 준다.</p>

<p>또한, NGC는 AI 모델 개발에 최적화된 Docker 이미지를 제공하며 TensorFlow, PyTorch 등 주요 프레임워크를 폭넓게 지원하여 GPU 관련 호환성 문제를 해결할 수 있다.</p>

<p>더 자세한 내용은 <a href="https://catalog.ngc.nvidia.com/containers"> NVIDIA NGC Catalog</a>에서 확인할 수 있으며, 안에서 <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/isaac-lab"> NVIDIA Isaac Lab</a>과 관련된 정보도 확인할 수 있다.</p>

<h3 id="2-build-the-isaac-lab-container">2. Build the Isaac Lab container</h3>

<p>Issac Lab 도커 이미지를 빌드하기 위해, Dockerfile과 docker-compose.yml, .env 파일을 포함하는 Root GitHub Repository를 클론한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git clone https://github.com/isaac-sim/IsaacLab.git
</code></pre></div></div>
<p>클론해온 <mark>IsaacLab</mark> 저장소의 <mark>./docker</mark> 디렉토리에는 Docker 및 ROS2 개발 환경을 구축하고 실행하는 데 필요한 파일들이 위치해 있다.</p>

<p><mark>container.py</mark>와 <mark>container.sh</mark>은 Isaac Lab의 Docker 컨테이너를 쉽게 실행하고 관리할 수 있도록 만들어진 Python 및 Bash 스크립트이다. 이를 활용하여 Docker 이미지를 빌드하고 컨테이너를 실행해보자.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd IsaacLab
$ python3 docker/container.py start
</code></pre></div></div>

<p><mark>container.py</mark>는 Docker 컨테이너를 관리하기 위한 CLI 명령어를 제공한다. 주요 명령어는 다음과 같다.</p>
<ul>
  <li><mark>start</mark>: 도커 이미지를 빌드하고 컨테이너를 백그라운드에서 실행</li>
  <li><mark>enter</mark>: 실행 중인 Isaac Lab 컨테이너에 새 bash 프로세스로 진입</li>
  <li><mark>config</mark>: 제공된 YAML 및 환경 파일을 기반으로 docker-compose.yaml 생성 또는 출력</li>
  <li><mark>copy</mark>: 컨테이너에서 빌드 결과물 및 로그 파일을 호스트로 복사</li>
  <li><mark>stop</mark>: 도커 컨테이너를 종료하고 삭제</li>
</ul>

<p>이미지 빌드가 완료되면 아래 명령어를 통해 컨테이너를 실행할 수 있다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python3 docker/container.py enter
</code></pre></div></div>

<p>이 환경에서는 Isaac Lab 저장소의 사본을 포함하며, Isaac Sim의 디렉토리와 라이브러리에 대한 액세스가 가능하다. 또한, 컨테이너에서는 호스트 장치의 <mark>IsaacLab</mark> 디렉토리가 마운트되어 있기 때문에 호스트에서 해당 디렉토리 아래의 파일을 수정하면 Docker 이미지를 다시 빌드할 필요 없이 변경 사항이 컨테이너에 즉시 반영된다.</p>

<h3 id="3-training-with-an-rl-agent">3. Training with an RL Agent</h3>

<p>이제 컨테이너 안에서 Isaac Lab 루트 디렉토리에 포함된 PPO 에이전트를 Stable-Baseline3를 사용하여 Cartpole balancing task를 해결하는 강화학습 예제를 실행해보고 결과를 확인해보자.</p>

<p>이 튜토리얼과 관련된 더 자세한 내용은 아래 링크를 통해 확인할 수 있다.</p>
<ul>
  <li><a href="https://isaac-sim.github.io/IsaacLab/main/source/tutorials/03_envs/run_rl_training.html"> Isaac Lab Documentation: Training with an RL Agent</a></li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --num_envs 64 --headless --video --max_iterations 2000

[INFO]: Time taken for scene creation : 1.056965 seconds
[INFO]: Scene manager:  &lt;class InteractiveScene&gt;
	Number of environments: 64
	Environment spacing   : 4.0
	Source prim name      : /World/envs/env_0
	Global prim paths     : []
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
</code></pre></div></div>

<p>에이전트를 훈련하는 세 가지 주요 방법이 있고, 플래그를 통해 설정할 수 있다.</p>

<ol>
  <li>Headless execution: <mark>--headless</mark> 플래그가 설정되면 시뮬레이션은 훈련 중에 렌더링되지 않는다. 일반적으로 물리 시뮬레이션 단계만 수행되기 때문에 훈련 프로세스가 빨라진다.</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --num_envs 64 --headless
</code></pre></div></div>

<ol>
  <li>Headless execution with off-screen render: 위의 headless 실행은 시뮬레이션을 렌더링하지 않기 때문에 훈련 중에 에이전트의 행동을 시각화할 수 없다. 에이전트의 행동을 시각화하기 위해 오프스크린 렌더링을 활성화(<mark>--enable_cameras</mark>)하고 훈련 중에 에이전트의 행동을 녹화(<mark>--video</mark>)하는 플래그를 전달한다.</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --num_envs 64 --headless --video
</code></pre></div></div>

<p>저장된 비디오는 <mark>logs/sb3/Isaac-Cartpole-v0/$run-dir/videos/train</mark> 디렉토리에 저장된다.</p>

<ol>
  <li>Interactive execution: 아래 명령어를 통해 실시간으로 에이전트가 시뮬레이션 환경과 상호 작용하며 훈련되고 있는지 확인할 수 있다. 하지만, 시뮬레이션이 화면에 렌더링되므로 훈련 프로세스가 느려질 수 있다. 해결 방법으로 화면 오른쪽 하단에 도킹된 창에서 다른 렌더링 모드 간에 전환할 수 있다.</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --num_envs 64
</code></pre></div></div>

<p>별도의 터미널에서 아래 명령을 실행하여 학습 진행 상황을 모니터링할 수 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./isaaclab.sh -p -m tensorboard.main --logdir logs/sb3/Isaac-Cartpole-v0
</code></pre></div></div>

<p>훈련이 완료되면 다음 명령을 실행하여 훈련된 에이전트를 Isaac Sim에서 시각화할 수 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./isaaclab.sh -p scripts/reinforcement_learning/sb3/play.py --task Isaac-Cartpole-v0 --num_envs 32 --use_last_checkpoint
</code></pre></div></div>

<h3 id="4-trained-agent-visualization">4. Trained Agent Visualization</h3>

<p>에이전트의 훈련이 완료되면 터미널에서 다음과 같은 로그를 확인할 수 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 293          |
|    ep_rew_mean          | 4.82         |
| time/                   |              |
|    fps                  | 6365         |
|    iterations           | 2000         |
|    time_elapsed         | 321          |
|    total_timesteps      | 2048000      |
| train/                  |              |
|    approx_kl            | 0.0043435125 |
|    clip_fraction        | 0.0512       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0181      |
|    explained_variance   | 0.57         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0119       |
|    n_updates            | 39980        |
|    policy_gradient_loss | -0.00246     |
|    std                  | 0.247        |
|    value_loss           | 0.017        |
------------------------------------------
Saving model checkpoint to /workspace/isaaclab/logs/sb3/Isaac-Cartpole-v0/2025-02-07_07-05-22/model_2048000_steps.zip
</code></pre></div></div>

<p>아래는 오프스크린 렌더링을 사용하여 에이전트의 훈련 중 행동을 스텝 0, 2000, 30000에서 저장된 영상과, 최종 훈련된 모델의 체크포인트를 로드하여 환경에서 에이전트를 실행한 결과를 시각화한 영상이다.</p>

<ul>
  <li>Step 0: Initial agent behavior at the beginning of training</li>
</ul>
<video width="640" height="360" controls="">
  <source src="/assets/img/blog/20250208/rl-video-step-0.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<ul>
  <li>Step 2000: Agent’s progress after 2000 steps of training</li>
</ul>
<video width="640" height="360" controls="">
  <source src="/assets/img/blog/20250208/rl-video-step-2000.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<ul>
  <li>Step 30000: Agent’s behavior after 30000 steps, nearing the end of training</li>
</ul>
<video width="640" height="360" controls="">
  <source src="/assets/img/blog/20250208/rl-video-step-30000.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<ul>
  <li>Final Model Execution: Agent performance after loading the final trained model checkpoint.</li>
</ul>
<video width="640" height="360" controls="">
  <source src="/assets/img/blog/20250208/isaaclab_rl_demo.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<p>다음 포스팅에서는 기본 환경 설정을 다룬 후 강체(rigid object), 관절(articulation), 변형 가능한 객체(deformable object)와의 상호작용에 대한 튜토리얼을 진행할 예정이다.</p>

<hr />]]></content><author><name>Minho Lee</name></author><category term="[&quot;Simulation&quot;]" /><category term="Robotics" /><category term="Isaac Lab" /><category term="Isaac Sim" /><summary type="html"><![CDATA[📌 최근 로봇 연구에서 로보틱스 시뮬레이션은 모델 성능 검증, 학습 워크플로우 구축, 대규모 합성데이터 생성 등 다양한 목적으로 활용되고 있다. 로봇 학습 및 시뮬레이션을 위한 여러 플랫폼이 존재하는 가운데, NVIDIA의 Isaac Lab은 GPU 가속, CUDA, TensorRT 등의 딥러닝 SDK와 Omniverse Isaac Sim을 기반으로 고품질 그래픽과 실시간 레이트레이싱을 지원하는 가상환경을 제공한다. 이러한 특징들은 Embodied AI를 연구하는 연구자들에게 강력하고 효과적인 솔루션이 될 수 있다.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roboxiv.com/assets/img/thumbnails/blog_2.png" /><media:content medium="image" url="https://roboxiv.com/assets/img/thumbnails/blog_2.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Foundation Models of and for Navigation</title><link href="https://roboxiv.com/study/2025/02/04/foundation-models-of-and-for-navigation/" rel="alternate" type="text/html" title="Foundation Models of and for Navigation" /><published>2025-02-04T00:00:00+00:00</published><updated>2025-02-04T00:00:00+00:00</updated><id>https://roboxiv.com/study/2025/02/04/foundation-models-of-and-for-navigation</id><content type="html" xml:base="https://roboxiv.com/study/2025/02/04/foundation-models-of-and-for-navigation/"><![CDATA[<p>📌 ICRA 2024 Workshop에서 열린 Vision-Language Models for Navigation and Manipulation (VLMNM)를 주제로 한 invited talk 중에서 ViNT, GNM, NoMaD 논문의 저자인 Dhruv Shah 박사님의 <strong>“Foundation Models of and for Navigation”</strong> 발표를 정리해보려고 한다.</p>

<p>워크숍에 대한 정보와 전체 발표 영상은 아래 링크를 통해 확인할 수 있다. <br /></p>
<ul>
  <li><a href="https://vlmnm-workshop.github.io/"> ICRA-24 VLMNM Workshop</a></li>
  <li><a href="https://www.youtube.com/playlist?list=PLvYJV1Xnj1YVZdTrP2i8EqJW7Ai_pIMV7"> Recordings of Invited Talks</a></li>
</ul>

<h3 id="1-foundation-models">1. Foundation Models</h3>
<p>로봇 분야의 최근의 발전을 보면, 중요한 핵심은 대량의 데이터를 활용한 학습에 있다. 다양한 작업에서 수집된 데이터를 통해 모델이 작업의 패턴을 학습하고 이를 활용하여 여러 작업을 수행할 수 있도록 하는 것이다. 이러한 모델들을 <strong>“Foundation Models”</strong>라고 한다. 일반적으로 이러한 Foundation Model들은 광범위한 데이터셋을 사용하여 자가 지도 학습을 통해 학습되며, 최소한의 지도 학습만으로도 뛰어난 일반화 및 적응 능력을 갖는 것이 특징이다.</p>

<p>이러한 모델들은 “인터넷 기반 모델 (Internet Foundation Models)”이라고 할 수도 있는데, 그 이유는 이런 모델들은 능동적으로 데이터를 수집하는 것이 아니라 인터넷에 존재하는 다양한 데이터들을 활용해 훈련되기 때문이다. 이러한 데이터와 모델의 통합은 data-driven robotics에서 중요한 역할을 할 수 있다.</p>

<p>모델을 훈련할 때 단순히 데이터의 규모만으로 충분한 것은 아니다. 모델의 성능을 높이기 위해서는 데이터의 품질과 다양성에 집중하는 데이터 중심적 접근(Data-centric perspective)이 중요하다. 그러나 이러한 고품질의 그리고 다양한 데이터를 수집하는 것은 매우 어렵고 비용이 많이 드는 문제이다.</p>

<p>이러한 관점에서 Dhruv Shah 박사는 <strong>기존에 존재하는 데이터를 활용하여 데이터 기반 로보틱스를 어떻게 실현할 것인지</strong>에 집중해 왔다. 기존 데이터들은 서로 다른 환경과 다양한 작업에서 수집되어 겉보기에는 매우 이질적으로 보일 수 있다. 그러나 적절한 목표와 구조를 정의하면 이러한 데이터를 효과적으로 활용하여 로봇 간 전이 가능한 유용한 표현을 학습할 수 있음을 보여주었다.</p>

<p align="center"><img src="/assets/img/blog/20250204/fig_1.png" /></p>

<h3 id="2-robot-foundation-model">2. Robot Foundation Model</h3>
<p>Robot Foundation Model이란 용어는 많은 의미를 포함하고 있으며, 사람들마다 각자 다른 방식으로 이해할 수도 있다. Dhruv Shah 박사는 연구에서 Robot Foundation Model을 한 번 훈련되면 추가적인 지도 학습 없이도 다양한 로봇에서 바로 사용할 수 있는 모델이라 정의하였다. 이는 서로 다른 센서를 가진 로봇, 전혀 다른 환경에 놓인 로봇에서도 새로운 작업을 수행할 수 있도록 설계된 모델을 의미한다. 이를 위해서 모델이 충족해야 하는 주요 조건은 아래와 같다:</p>

<p align="center"><img src="/assets/img/blog/20250204/fig_2.png" /></p>

<p>이러한 모델을 만들기 위해서는 기존의 개별적인 로봇별 학습 방식에서 벗어나, 여러 로봇에서 수집한 데이터를 통합하여 단일한 거대 신경망 모델을 학습하는 방식 (Cross-Embodiment Learning)이 요구된다.</p>

<h3 id="3-cross-embodiment-learning">3. Cross-Embodiment Learning</h3>
<p>서로 다른 로봇 데이터를 하나의 모델에서 학습시키기 위해서는 특정한 설계 원칙이 필요하다. <br /></p>
<ul>
  <li><strong>공통된 행동 공간(action space) 정의</strong>: 각 로봇은 서로 다른 행동 공간(rotor velocities, joint angles …)을 가진다. 따라서, 이를 통합할 수 있는 공통된 표현이 필요하다.</li>
  <li><strong>로봇의 특성을 반영하는 프롬프트 (Embodiment Prompt)</strong>: 로봇마다 구조나 이동 방식이 다르기 때문에, 모든 로봇에 동일한 방식의 제어 모델을 적용하기 어렵다. 이를 해결하기 위해 로봇의 특성을 명시적인 시스템 파라미터로 직접 학습하는 대신 로봇이 과거에 수행한 행동 데이터를 활용하여 모델이 스스로 로봇의 특성을 학습하도록 하는 접근 방식이 요구된다. 다시 말해, Embodiment Prompt란 로봇의 과거 행동 데이터를 입력으로 제공하여 모델이 해당 로봇의 특성을 자동으로 반영하는 기법을 의미한다.</li>
</ul>

<p>개별 로봇 데이터만 학습한 모델보다, 여러 로봇의 데이터를 통합해 학습한 모델(GNM, General Navigation Model)이 일관되게 높은 성능을 기록함을 보여주었다. 또한, 개별 로봇에서 학습한 정책보다 다수의 로봇 데이터를 결합한 정책이 더욱 일반화된 성능을 보이며, 모델의 크기가 커질 때에도 성능이 더 크게 향상됨을 보였다.</p>

<ul>
  <li><a href="https://ieeexplore.ieee.org/abstract/document/10161227?casa_token=UShbqLF5uogAAAAA:s3h6WmqvbkyN8E8lCbVogL2PXPrGoii7FftHRSKsFySo2NEW0aLQb5dF1A2OLe2KZIligpBP"> Shah, Dhruv, et al. “Gnm: A general navigation model to drive any robot.” 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2023.</a></li>
</ul>
<p align="center"><img src="/assets/img/blog/20250204/fig_3.gif" /></p>

<h3 id="4-downstream-adaptation">4. Downstream Adaptation</h3>
<p align="center"><img src="/assets/img/blog/20250204/fig_4.png" /></p>

<p>제안하고 있는 Robot Foundation Model을 기반으로 더 고차원의 기능을 추가하기 위한 연구가 진행되고 있다. 주요 연구 방향은 크게 세 가지로 나뉘는데, 기본적으로 학습된 모델은 단순히 목표 지점에 도달하고 충돌을 회피하는 기능만을 수행한다면 기존 모델에 약간의 추가 데이터와 적절한 보상 함수를 사용해 학습시켜 로봇이 사회적 상호작용이 이루어지는 환경에서 더 나은 행동을 학습할 수 있도록 하는 연구가 진행되고 있다.</p>

<p>두 번째로 기존의 모델이 이미지 기반 목표를 사용했다면, 텍스트 기반 목표 또는 GPS 기반 목표를 적용하는 것이 더 유용할 수 있다고 판단하여 연구가 수행되고 있다. 그러나, 텍스트 기반 목표를 적용하려면 모든 데이터를 텍스트로 annotation해야 하는 문제가 있다. 이를 해결하기 위해 이미지 기반 정책을 학습한 후, GPS 좌표나 명령어를 인코딩하는 새로운 모듈을 추가하는 방식을 사용했다고 한다. 이 방식은 GPT 모델에서 소프트 프롬프팅(Soft Prompting)을 사용하는 방식과 유사하며, 향후 연구에서는 In-context Prompting 방식을 활용해 더욱 효과적인 목표 설정을 탐구할 예정이라고 한다.</p>

<p>마지막으로 대규모의 로봇 데이터셋 구축(Open Cross-Embodiment Collaboration)이 진행 중이다. 연구 결과에서 더 다양한 로봇 데이터를 통합할 수록 Positive Transfer 현상이 발생함을 확인하였으며, 특히 manipulation과 navigation tasks를 함께 정책으로 학습할 경우에 두 작업 모두에서 성능이 개선되는 효과가 나타났다. 이러한 연구를 바탕으로 더 다양한 로봇과 작업 데이터를 동시에 학습하는 하나의 통합된 모델로의 확장 연구가 진행되고 있다고 한다.</p>

<h3 id="5-conclusion">5. Conclusion</h3>
<p>발표 내용을 요약하면 다음과 같다:</p>

<ul>
  <li>로봇 분야에서 <u>Foundation Models</u>은 일반적으로 대량의 데이터를 활용하여 로봇이 다양한 작업의 패턴을 학습하고, 이를 통해 여러 작업을 수행 가능하도록 하는 모델을 의미한다.</li>
  <li>모델을 훈련할 때 데이터의 규모만으로 충분하지 않으며, 데이터의 품질과 다양성에 집중하는 <u>Data-centric Perspective</u>가 중요하다. 하지만, 고품질 데이터를 확보하는 것은 높은 비용과 어려움이 따르는 문제이다.</li>
  <li>Dhruv Shah 박사는 연구에서 <u>Robot Foundation Model</u>을 추가적인 지도 학습 없이도 다양한 로봇에서 바로 사용 가능하며, 이종 센서나 새로운 환경에서도 적용될 수 있도록 설계된 모델이라 정의했다.</li>
  <li>위의 모델을 설계하기 위해서는 <u>Cross-Embodiment Learning</u>의 개념이 필요하며, 이는 서로 다른 로봇의 행동 공간을 통합하고 로봇의 특성을 반영하는 프롬프트를 활용하여 모델을 학습하는 방식이다. 이를 통해 개별적인 학습보다, 보다 일관적이고 일반화된 성능을 보인다는 것이 실험적으로 입증되었다.</li>
  <li>향후 연구에서는 기존 모델에 <u>사회적 보상함수 추가</u>, <u>새로운 모달리티(텍스트/GPS 기반 목표) 적용</u>, <u>더 많은 로봇 모델 및 작업을 학습한 통합 모델로의 확장</u>의 방향이 진행될 것이다.</li>
</ul>

<p>끝으로, 앞서 언급된 모델 및 관련 프레임워크는 아래 GitHub에서 확인할 수 있다.</p>
<ul>
  <li><a href="https://github.com/robodhruv/visualnav-transformer"> Berkeley AI Research &amp; Dhruv Shah Github</a></li>
</ul>

<p>내가 연구하는 필드에서 Dhruv Shah 박사님의 연구들은 큰 주목을 받았었고, 현재도 많은 관심을 받고 있다. 앞으로도 의미 있는 연구들이 나올 것으로 기대되기 때문에, 계속해서 살펴볼 예정이다.
그리고 GitHub에 공개된 사전 학습된 모델을 연구실의 로봇 플랫폼에 적용하고 다양한 모듈과 연계하여 실험해 볼 계획인데, 아주 흥미로운 작업이 될 것 같다!</p>

<hr />]]></content><author><name>Minho Lee</name></author><category term="[&quot;Study&quot;]" /><category term="ICRA2024" /><category term="Workshop" /><category term="Foundation Model" /><category term="Robotics" /><category term="Navigation" /><summary type="html"><![CDATA[📌 ICRA 2024 Workshop에서 열린 Vision-Language Models for Navigation and Manipulation (VLMNM)를 주제로 한 invited talk 중에서 ViNT, GNM, NoMaD 논문의 저자인 Dhruv Shah 박사님의 “Foundation Models of and for Navigation” 발표를 정리해보려고 한다.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roboxiv.com/assets/img/thumbnails/blog_1.png" /><media:content medium="image" url="https://roboxiv.com/assets/img/thumbnails/blog_1.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>